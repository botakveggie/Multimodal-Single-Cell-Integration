{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import hdf5plugin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "metadata"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/j1ptm9m13mn79nytwqyc4lqh0000gn/T/ipykernel_54176/381293118.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_multiome.drop('technology', axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119651</th>\n",
       "      <td>458c2ae2c9b1</td>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119652</th>\n",
       "      <td>01a0659b0710</td>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119653</th>\n",
       "      <td>028a8bc3f2ba</td>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119654</th>\n",
       "      <td>7ec0ca8bb863</td>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119655</th>\n",
       "      <td>caa0b0022cdc</td>\n",
       "      <td>2</td>\n",
       "      <td>27678</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281523</th>\n",
       "      <td>96a60b026659</td>\n",
       "      <td>10</td>\n",
       "      <td>31800</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281524</th>\n",
       "      <td>d493e546991e</td>\n",
       "      <td>10</td>\n",
       "      <td>31800</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281525</th>\n",
       "      <td>05666c99aa48</td>\n",
       "      <td>10</td>\n",
       "      <td>31800</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281526</th>\n",
       "      <td>121f946642b5</td>\n",
       "      <td>10</td>\n",
       "      <td>31800</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281527</th>\n",
       "      <td>b847ba21f59f</td>\n",
       "      <td>10</td>\n",
       "      <td>31800</td>\n",
       "      <td>hidden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161877 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cell_id  day  donor cell_type\n",
       "119651  458c2ae2c9b1    2  27678    hidden\n",
       "119652  01a0659b0710    2  27678    hidden\n",
       "119653  028a8bc3f2ba    2  27678    hidden\n",
       "119654  7ec0ca8bb863    2  27678    hidden\n",
       "119655  caa0b0022cdc    2  27678    hidden\n",
       "...              ...  ...    ...       ...\n",
       "281523  96a60b026659   10  31800    hidden\n",
       "281524  d493e546991e   10  31800    hidden\n",
       "281525  05666c99aa48   10  31800    hidden\n",
       "281526  121f946642b5   10  31800    hidden\n",
       "281527  b847ba21f59f   10  31800    hidden\n",
       "\n",
       "[161877 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi Metadata\n",
    "file_path = 'metadata/metadata.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_multiome = df[df['technology']!='citeseq'] # Removing data for citeseq\n",
    "# df.shape # (161877, 5)\n",
    "df_multiome.drop('technology', axis=1, inplace=True)\n",
    "df_multiome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "metadata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             cell_id  day  donor cell_type\n",
      "0       c2150f55becb    2  27678       HSC\n",
      "1       65b7edf8a4da    2  27678       HSC\n",
      "2       c1b26cb1057b    2  27678      EryP\n",
      "3       917168fa6f83    2  27678      NeuP\n",
      "4       2b29feeca86d    2  27678      EryP\n",
      "...              ...  ...    ...       ...\n",
      "119646  a9b4d99f1f50    7  31800       HSC\n",
      "119647  0e2c1d0782af    7  31800       HSC\n",
      "119648  a3cbc5aa0ec3    7  31800       MkP\n",
      "119649  75b350243add    7  31800      EryP\n",
      "119650  ad5a949989b2    7  31800      EryP\n",
      "\n",
      "[119651 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/j1ptm9m13mn79nytwqyc4lqh0000gn/T/ipykernel_54176/1824312801.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_citeseq.drop('technology', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Citeseq Metadata\n",
    "file_path = 'metadata/metadata.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_citeseq = df[df['technology']=='citeseq'] # Only keeping data for citeseq\n",
    "# print(df.shape) # (281528, 5)\n",
    "df_citeseq.drop('technology', axis=1, inplace=True)\n",
    "print(df_citeseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITESeq Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = \"data/train_cite_targets.h5\"\n",
    "f = h5py.File(train_targets,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['axis0', 'axis1', 'block0_items', 'block0_values']>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## >>> f['train_cite_targets'].keys()\n",
    "## ['axis0', 'axis1', 'block0_items', 'block0_values']\n",
    "## ### axis0 is the protein namess. \n",
    "## ### axis1 is ???\n",
    "## ### block0_items is also gene ids, same as axis0\n",
    "## ### axis1 is a matrix. rows are gene ids and cols ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70988,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f['train_cite_targets']['axis0'].shape            # (140,)\n",
    "# f['train_cite_targets']['axis1'].shape            # (70988,)\n",
    "# f['train_cite_targets']['block0_items'].shape     # (140,)\n",
    "# f['train_cite_targets']['block0_values'].shape    # (70988, 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'45006fe3e4c8', b'd02759a80ba2', b'c016c6b0efa5', b'ba7f733a4f75',\n",
       "       b'fbcf2443ffb2'], dtype='|S12')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['train_cite_targets']['axis1'][:5]\n",
    "# f['train_cite_targets']['block0_items'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         c2150f55becb\n",
      "1         65b7edf8a4da\n",
      "2         c1b26cb1057b\n",
      "3         917168fa6f83\n",
      "4         2b29feeca86d\n",
      "              ...     \n",
      "119646    a9b4d99f1f50\n",
      "119647    0e2c1d0782af\n",
      "119648    a3cbc5aa0ec3\n",
      "119649    75b350243add\n",
      "119650    ad5a949989b2\n",
      "Name: cell_id, Length: 119651, dtype: object\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df_citeseq['cell_id'])\n",
    "# print(df['cell_id'])\n",
    "print('c2150f55becb'  in df['cell_id'].values[0]) # Sanity check that we can search for cell ids\n",
    "print('45006fe3e4c8' in df['cell_id'].values[0]) # first value in axis1 not found in cite['cell_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITESeq Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = \"data/train_cite_inputs.h5\"\n",
    "f = h5py.File(train_inputs,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f['train_cite_inputs']['axis0'].shape)            # (22050,)\n",
    "# print(f['train_cite_inputs']['axis1'].shape)            # (70988,)\n",
    "# print(f['train_cite_inputs']['block0_items'].shape)     # (22050,)\n",
    "# print(f['train_cite_inputs']['block0_values'].shape)    # (70988, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'45006fe3e4c8', b'd02759a80ba2', b'c016c6b0efa5', b'ba7f733a4f75',\n",
       "       b'fbcf2443ffb2'], dtype='|S12')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['train_cite_targets']['axis1'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1678035 , 0.62253   , 0.10695851, 0.32498938, 3.331674  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['train_cite_targets']['block0_values'][0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key of <f['train_multi_targets']>: axis0\n",
      "<HDF5 dataset \"axis0\": shape (23418,), type \"|S15\">\n",
      "key of <f['train_multi_targets']>: axis1\n",
      "<HDF5 dataset \"axis1\": shape (105942,), type \"|S12\">\n",
      "key of <f['train_multi_targets']>: block0_items\n",
      "<HDF5 dataset \"block0_items\": shape (23418,), type \"|S15\">\n",
      "key of <f['train_multi_targets']>: block0_values\n",
      "<HDF5 dataset \"block0_values\": shape (105942, 23418), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "for k,v in f['train_multi_targets'].items():\n",
    "    print(f'key of <f[\\'train_multi_targets\\']>: {k}')\n",
    "    print(f['train_multi_targets'][k])\n",
    "    # print(help(f['train_multi_targets'][k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dataset in module h5py._hl.dataset object:\n",
      "\n",
      "class Dataset(h5py._hl.base.HLObject)\n",
      " |  Dataset(bind, *, readonly=False)\n",
      " |  \n",
      " |  Represents an HDF5 dataset\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      h5py._hl.base.HLObject\n",
      " |      h5py._hl.base.CommonStateObject\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |      Create a Numpy array containing the whole dataset.  DON'T THINK\n",
      " |      THIS MEANS DATASETS ARE INTERCHANGEABLE WITH ARRAYS.  For one thing,\n",
      " |      you have to read the whole dataset every time this method is called.\n",
      " |  \n",
      " |  __getitem__(self, args, new_dtype=None)\n",
      " |      Read a slice from the HDF5 dataset.\n",
      " |      \n",
      " |      Takes slices and recarray-style field names (more than one is\n",
      " |      allowed!) in any order.  Obeys basic NumPy rules, including\n",
      " |      broadcasting.\n",
      " |      \n",
      " |      Also supports:\n",
      " |      \n",
      " |      * Boolean \"mask\" array indexing\n",
      " |  \n",
      " |  __init__(self, bind, *, readonly=False)\n",
      " |      Create a new Dataset object by binding to a low-level DatasetID.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      BEWARE: Modifications to the yielded data are *NOT* written to file.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Limited to 2**32 on 32-bit systems; Dataset.len() is preferred.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setitem__(self, args, val)\n",
      " |      Write to the HDF5 dataset from a Numpy array.\n",
      " |      \n",
      " |      NumPy's broadcasting rules are honored, for \"simple\" indexing\n",
      " |      (slices and integers).  For advanced indexing, the shapes must\n",
      " |      match.\n",
      " |  \n",
      " |  asstr(self, encoding=None, errors='strict')\n",
      " |      Get a wrapper to read string data as Python strings:\n",
      " |      \n",
      " |      >>> str_array = dataset.asstr()[:]\n",
      " |      \n",
      " |      The parameters have the same meaning as in ``bytes.decode()``.\n",
      " |      If ``encoding`` is unspecified, it will use the encoding in the HDF5\n",
      " |      datatype (either ascii or utf-8).\n",
      " |  \n",
      " |  astype(self, dtype)\n",
      " |      Get a wrapper allowing you to perform reads to a\n",
      " |      different destination type, e.g.:\n",
      " |      \n",
      " |      >>> double_precision = dataset.astype('f8')[0:100:2]\n",
      " |  \n",
      " |  fields(self, names, *, _prior_dtype=None)\n",
      " |      Get a wrapper to read a subset of fields from a compound data type:\n",
      " |      \n",
      " |      >>> 2d_coords = dataset.fields(['x', 'y'])[:]\n",
      " |      \n",
      " |      If names is a string, a single field is extracted, and the resulting\n",
      " |      arrays will have that dtype. Otherwise, it should be an iterable,\n",
      " |      and the read data will have a compound dtype.\n",
      " |  \n",
      " |  flush(self)\n",
      " |      Flush the dataset data and metadata to the file.\n",
      " |      If the dataset is chunked, raw data chunks are written to the file.\n",
      " |      \n",
      " |      This is part of the SWMR features and only exist when the HDF5\n",
      " |      library version >=1.9.178\n",
      " |  \n",
      " |  iter_chunks(self, sel=None)\n",
      " |      Return chunk iterator.  If set, the sel argument is a slice or\n",
      " |      tuple of slices that defines the region to be used. If not set, the\n",
      " |      entire dataspace will be used for the iterator.\n",
      " |      \n",
      " |      For each chunk within the given region, the iterator yields a tuple of\n",
      " |      slices that gives the intersection of the given chunk with the\n",
      " |      selection area.\n",
      " |      \n",
      " |      A TypeError will be raised if the dataset is not chunked.\n",
      " |      \n",
      " |      A ValueError will be raised if the selection region is invalid.\n",
      " |  \n",
      " |  len(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Use of this method is preferred to len(dset), as Python's built-in\n",
      " |      len() cannot handle values greater then 2**32 on 32-bit systems.\n",
      " |  \n",
      " |  make_scale(self, name='')\n",
      " |      Make this dataset an HDF5 dimension scale.\n",
      " |      \n",
      " |      You can then attach it to dimensions of other datasets like this::\n",
      " |      \n",
      " |          other_ds.dims[0].attach_scale(ds)\n",
      " |      \n",
      " |      You can optionally pass a name to associate with this scale.\n",
      " |  \n",
      " |  read_direct(self, dest, source_sel=None, dest_sel=None)\n",
      " |      Read data directly from HDF5 into an existing NumPy array.\n",
      " |      \n",
      " |      The destination array must be C-contiguous and writable.\n",
      " |      Selections must be the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  refresh(self)\n",
      " |      Refresh the dataset metadata by reloading from the file.\n",
      " |      \n",
      " |      This is part of the SWMR features and only exist when the HDF5\n",
      " |      library version >=1.9.178\n",
      " |  \n",
      " |  resize(self, size, axis=None)\n",
      " |      Resize the dataset, or the specified axis.\n",
      " |      \n",
      " |      The dataset must be stored in chunked format; it can be resized up to\n",
      " |      the \"maximum shape\" (keyword maxshape) specified at creation time.\n",
      " |      The rank of the dataset cannot be changed.\n",
      " |      \n",
      " |      \"Size\" should be a shape tuple, or if an axis is specified, an integer.\n",
      " |      \n",
      " |      BEWARE: This functions differently than the NumPy resize() method!\n",
      " |      The data is not \"reshuffled\" to fit in the new shape; each axis is\n",
      " |      grown or shrunk independently.  The coordinates of existing data are\n",
      " |      fixed.\n",
      " |  \n",
      " |  virtual_sources(self)\n",
      " |      Get a list of the data mappings for a virtual dataset\n",
      " |  \n",
      " |  write_direct(self, source, source_sel=None, dest_sel=None)\n",
      " |      Write data directly to HDF5 from a NumPy array.\n",
      " |      \n",
      " |      The source array must be C-contiguous.  Selections must be\n",
      " |      the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  chunks\n",
      " |      Dataset chunks (or None)\n",
      " |  \n",
      " |  compression\n",
      " |      Compression strategy (or None)\n",
      " |  \n",
      " |  compression_opts\n",
      " |      Compression setting.  Int(0-9) for gzip, 2-tuple for szip.\n",
      " |  \n",
      " |  dims\n",
      " |      Access dimension scales attached to this dataset.\n",
      " |  \n",
      " |  dtype\n",
      " |      Numpy dtype representing the datatype\n",
      " |  \n",
      " |  external\n",
      " |      External file settings. Returns a list of tuples of\n",
      " |      (name, offset, size) for each external file entry, or returns None\n",
      " |      if no external files are used.\n",
      " |  \n",
      " |  fillvalue\n",
      " |      Fill value for this dataset (0 by default)\n",
      " |  \n",
      " |  fletcher32\n",
      " |      Fletcher32 filter is present (T/F)\n",
      " |  \n",
      " |  is_virtual\n",
      " |      Check if this is a virtual dataset\n",
      " |  \n",
      " |  maxshape\n",
      " |      Shape up to which this dataset can be resized.  Axes with value\n",
      " |      None have no resize limit.\n",
      " |  \n",
      " |  nbytes\n",
      " |      Numpy-style attribute giving the raw dataset size as the number of bytes\n",
      " |  \n",
      " |  ndim\n",
      " |      Numpy-style attribute giving the number of dimensions\n",
      " |  \n",
      " |  scaleoffset\n",
      " |      Scale/offset filter settings. For integer data types, this is\n",
      " |      the number of bits stored, or 0 for auto-detected. For floating\n",
      " |      point data types, this is the number of decimal places retained.\n",
      " |      If the scale/offset filter is not in use, this is None.\n",
      " |  \n",
      " |  shuffle\n",
      " |      Shuffle filter present (T/F)\n",
      " |  \n",
      " |  size\n",
      " |      Numpy-style attribute giving the total dataset size\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  shape\n",
      " |      Numpy-style shape tuple giving dataset dimensions\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __getnewargs__(self)\n",
      " |      Disable pickle.\n",
      " |      \n",
      " |      Handles for HDF5 objects can't be reliably deserialised, because the\n",
      " |      recipient may not have access to the same files. So we do this to\n",
      " |      fail early.\n",
      " |      \n",
      " |      If you really want to pickle h5py objects and can live with some\n",
      " |      limitations, look at the h5pickle project on PyPI.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  attrs\n",
      " |      Attributes attached to this object\n",
      " |  \n",
      " |  file\n",
      " |      Return a File instance associated with this object\n",
      " |  \n",
      " |  id\n",
      " |      Low-level identifier appropriate for this object\n",
      " |  \n",
      " |  name\n",
      " |      Return the full name of this object.  None if anonymous.\n",
      " |  \n",
      " |  parent\n",
      " |      Return the parent group of this object.\n",
      " |      \n",
      " |      This is always equivalent to obj.file[posixpath.dirname(obj.name)].\n",
      " |      ValueError if this object is anonymous.\n",
      " |  \n",
      " |  ref\n",
      " |      An (opaque) HDF5 reference to this object\n",
      " |  \n",
      " |  regionref\n",
      " |      Create a region reference (Datasets only).\n",
      " |      \n",
      " |      The syntax is regionref[<slices>]. For example, dset.regionref[...]\n",
      " |      creates a region reference in which the whole dataset is selected.\n",
      " |      \n",
      " |      Can also be used to determine the shape of the referenced dataset\n",
      " |      (via .shape property), or the shape of the selection (via the\n",
      " |      .selection property).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.CommonStateObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(f['train_multi_targets']['axis0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ENSG00000121410'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['train_multi_targets']['axis0'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = \"data/train_multi_inputs.h5\"\n",
    "f_in = h5py.File(train_inputs)\n",
    "for i in f:\n",
    "    group = ((f[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"axis0\": shape (23418,), type \"|S15\">"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group['axis0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/minhanchoo/GitHub/Multimodal Single Cell Integration/Multimodal-Single-Cell-Integration/metadata_explore.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/minhanchoo/GitHub/Multimodal%20Single%20Cell%20Integration/Multimodal-Single-Cell-Integration/metadata_explore.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_multi_train_x \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_hdf(train_inputs, start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, stop\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/pytables.py:438\u001b[0m, in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m groups \u001b[39m=\u001b[39m store\u001b[39m.\u001b[39mgroups()\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataset(s) incompatible with Pandas data types, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot table, or no datasets found in HDF5 file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m candidate_only_group \u001b[39m=\u001b[39m groups[\u001b[39m0\u001b[39m]\n\u001b[1;32m    444\u001b[0m \u001b[39m# For the HDF file to have only one dataset, all other groups\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# should then be metadata groups for that candidate group. (This\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# assumes that the groups() method enumerates parent groups\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m# before their children.)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file."
     ]
    }
   ],
   "source": [
    "df_multi_train_x = pd.read_hdf(train_inputs, start=0, stop=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi_train_y = pd.read_hdf(train_targets, start=0, stop=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410</th>\n",
       "      <th>ENSG00000268895</th>\n",
       "      <th>ENSG00000175899</th>\n",
       "      <th>ENSG00000245105</th>\n",
       "      <th>ENSG00000166535</th>\n",
       "      <th>ENSG00000256661</th>\n",
       "      <th>ENSG00000184389</th>\n",
       "      <th>ENSG00000128274</th>\n",
       "      <th>ENSG00000094914</th>\n",
       "      <th>ENSG00000081760</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000086827</th>\n",
       "      <th>ENSG00000174442</th>\n",
       "      <th>ENSG00000122952</th>\n",
       "      <th>ENSG00000198205</th>\n",
       "      <th>ENSG00000198455</th>\n",
       "      <th>ENSG00000070476</th>\n",
       "      <th>ENSG00000203995</th>\n",
       "      <th>ENSG00000162378</th>\n",
       "      <th>ENSG00000159840</th>\n",
       "      <th>ENSG00000074755</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56390cf1b95e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.893861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.583255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.893861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc0c60183c33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b4a87e22ad0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.107832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.107832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81cccad8cd81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.507936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.195558</td>\n",
       "      <td>4.507936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.195558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15cb3d85c232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.531572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.842377</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22f7100af78b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.766403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648874e21d10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.435873</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11e1bdb49257</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.518555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.518555</td>\n",
       "      <td>4.518555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76014717c09b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.217422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.217422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.217422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb40f3dea8dd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.315822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.719647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 23418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410  ENSG00000268895  ENSG00000175899  \\\n",
       "cell_id                                                           \n",
       "56390cf1b95e              0.0         0.000000              0.0   \n",
       "fc0c60183c33              0.0         0.000000              0.0   \n",
       "9b4a87e22ad0              0.0         0.000000              0.0   \n",
       "81cccad8cd81              0.0         4.507936              0.0   \n",
       "15cb3d85c232              0.0         0.000000              0.0   \n",
       "...                       ...              ...              ...   \n",
       "22f7100af78b              0.0         0.000000              0.0   \n",
       "648874e21d10              0.0         0.000000              0.0   \n",
       "11e1bdb49257              0.0         0.000000              0.0   \n",
       "76014717c09b              0.0         0.000000              0.0   \n",
       "fb40f3dea8dd              0.0         0.000000              0.0   \n",
       "\n",
       "gene_id       ENSG00000245105  ENSG00000166535  ENSG00000256661  \\\n",
       "cell_id                                                           \n",
       "56390cf1b95e              0.0              0.0              0.0   \n",
       "fc0c60183c33              0.0              0.0              0.0   \n",
       "9b4a87e22ad0              0.0              0.0              0.0   \n",
       "81cccad8cd81              0.0              0.0              0.0   \n",
       "15cb3d85c232              0.0              0.0              0.0   \n",
       "...                       ...              ...              ...   \n",
       "22f7100af78b              0.0              0.0              0.0   \n",
       "648874e21d10              0.0              0.0              0.0   \n",
       "11e1bdb49257              0.0              0.0              0.0   \n",
       "76014717c09b              0.0              0.0              0.0   \n",
       "fb40f3dea8dd              0.0              0.0              0.0   \n",
       "\n",
       "gene_id       ENSG00000184389  ENSG00000128274  ENSG00000094914  \\\n",
       "cell_id                                                           \n",
       "56390cf1b95e              0.0              0.0         0.000000   \n",
       "fc0c60183c33              0.0              0.0         0.000000   \n",
       "9b4a87e22ad0              0.0              0.0         0.000000   \n",
       "81cccad8cd81              0.0              0.0         0.000000   \n",
       "15cb3d85c232              0.0              0.0         0.000000   \n",
       "...                       ...              ...              ...   \n",
       "22f7100af78b              0.0              0.0         4.766403   \n",
       "648874e21d10              0.0              0.0         4.747074   \n",
       "11e1bdb49257              0.0              0.0         0.000000   \n",
       "76014717c09b              0.0              0.0         0.000000   \n",
       "fb40f3dea8dd              0.0              0.0         0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760  ...  ENSG00000086827  ENSG00000174442  \\\n",
       "cell_id                        ...                                     \n",
       "56390cf1b95e              0.0  ...              0.0         0.000000   \n",
       "fc0c60183c33              0.0  ...              0.0         0.000000   \n",
       "9b4a87e22ad0              0.0  ...              0.0         0.000000   \n",
       "81cccad8cd81              0.0  ...              0.0         5.195558   \n",
       "15cb3d85c232              0.0  ...              0.0         0.000000   \n",
       "...                       ...  ...              ...              ...   \n",
       "22f7100af78b              0.0  ...              0.0         0.000000   \n",
       "648874e21d10              0.0  ...              0.0         0.000000   \n",
       "11e1bdb49257              0.0  ...              0.0         0.000000   \n",
       "76014717c09b              0.0  ...              0.0         0.000000   \n",
       "fb40f3dea8dd              0.0  ...              0.0         0.000000   \n",
       "\n",
       "gene_id       ENSG00000122952  ENSG00000198205  ENSG00000198455  \\\n",
       "cell_id                                                           \n",
       "56390cf1b95e         4.893861              0.0              0.0   \n",
       "fc0c60183c33         0.000000              0.0              0.0   \n",
       "9b4a87e22ad0         5.107832              0.0              0.0   \n",
       "81cccad8cd81         4.507936              0.0              0.0   \n",
       "15cb3d85c232         0.000000              0.0              0.0   \n",
       "...                       ...              ...              ...   \n",
       "22f7100af78b         0.000000              0.0              0.0   \n",
       "648874e21d10         0.000000              0.0              0.0   \n",
       "11e1bdb49257         0.000000              0.0              0.0   \n",
       "76014717c09b         0.000000              0.0              0.0   \n",
       "fb40f3dea8dd         5.315822              0.0              0.0   \n",
       "\n",
       "gene_id       ENSG00000070476  ENSG00000203995  ENSG00000162378  \\\n",
       "cell_id                                                           \n",
       "56390cf1b95e         0.000000              0.0         5.583255   \n",
       "fc0c60183c33         0.000000              0.0         0.000000   \n",
       "9b4a87e22ad0         0.000000              0.0         0.000000   \n",
       "81cccad8cd81         0.000000              0.0         0.000000   \n",
       "15cb3d85c232         5.531572              0.0         0.000000   \n",
       "...                       ...              ...              ...   \n",
       "22f7100af78b         0.000000              0.0         0.000000   \n",
       "648874e21d10         4.747074              0.0         0.000000   \n",
       "11e1bdb49257         4.518555              0.0         0.000000   \n",
       "76014717c09b         4.217422              0.0         4.217422   \n",
       "fb40f3dea8dd         5.719647              0.0         0.000000   \n",
       "\n",
       "gene_id       ENSG00000159840  ENSG00000074755  \n",
       "cell_id                                         \n",
       "56390cf1b95e         0.000000         4.893861  \n",
       "fc0c60183c33         0.000000         0.000000  \n",
       "9b4a87e22ad0         0.000000         5.107832  \n",
       "81cccad8cd81         0.000000         5.195558  \n",
       "15cb3d85c232         4.842377         0.000000  \n",
       "...                       ...              ...  \n",
       "22f7100af78b         0.000000         0.000000  \n",
       "648874e21d10         5.435873         0.000000  \n",
       "11e1bdb49257         4.518555         4.518555  \n",
       "76014717c09b         0.000000         4.217422  \n",
       "fb40f3dea8dd         0.000000         0.000000  \n",
       "\n",
       "[1000 rows x 23418 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multi_train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
